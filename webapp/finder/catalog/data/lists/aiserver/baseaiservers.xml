<?xml version="1.0" encoding="UTF-8"?>

<root>

	<data id="1" aifunction="ai_translate_server" ordering="1" serverroot="http://libretranslate.entermediadb.net:48991" serverkey="4b37163c-11dd-4a14-be24-f8fc318f703e">
		<name><![CDATA[AI: Translate Server]]></name>
	</data>

	<data id="2" aifunction="ai_vectorizer_server" ordering="1" serverroot="http://vectorizerem.entermediadb.net:48981" serverkey="4b37163c-11dd-4a14-be24-f8fc318f703e">
		<name><![CDATA[AI: Vectorizer Server]]></name>
	</data>

	<data id="3" aifunction="ai_transcriber_server" ordering="1" serverroot="http://transcriber.entermediadb.net:48971" serverkey="4b37163c-11dd-4a14-be24-f8fc318f703e">
		<name><![CDATA[AI: Transcriber Server]]></name>
	</data>

	<data id="4" aifunction="ai_llmembedding_server" ordering="1" serverroot="https://documentembedding.entermediadb.net" serverkey="demo">
		<name><![CDATA[AI: Embedding Server]]></name>
	</data>

	<data id="5" aifunction="classifyAsset" ordering="1" serverroot="http://142.113.71.170:36143" serverkey="demo">
		<name><![CDATA[AI: Asset Classification Server]]></name>
	</data>
	
	<data id="5" aifunction="generateMarkdown" connectionbean="llamaVisionConnector" llmtype="llama" ordering="1" model="unsloth_Qwen3-VL-8B-Instruct-GGUF_Qwen3-VL-8B-Instruct-Q4_K_M.gguf" serverroot="http://142.113.71.170:36143" serverkey="demo">
		<name><![CDATA[AI: Generate Markdown]]></name>
	</data>
	

	<data id="6" aifunction="classifyEntity" ordering="1" serverroot="http://142.113.71.170:36143" serverkey="demo">
		<name><![CDATA[AI: Entity Classification Server]]></name>
	</data>

	<data id="6" aifunction="classifyEntity" ordering="1" serverroot="http://142.113.71.170:36143" serverkey="demo">
		<name><![CDATA[AI: Entity Classification Server]]></name>
	</data>

	<data id="7" aifunction="ai_create_asset_server" ordering="1" serverroot="https://api.openai.com" serverkey="OpenAIKey">
		<name><![CDATA[AI: Open AI Create Asset]]></name>
	</data>

	<data id="8" aifunction="ai_create_entity_server" ordering="1" serverroot="https://api.openai.com" serverkey="OpenAIKey">
		<name><![CDATA[AI: Open AI Create Entity]]></name>
	</data>

 	<data id="9" bean="documentSplit" model="" serverroot="https://api.openai.com" >
      <name>
         <language id="en"><![CDATA[Document Split]]></language>
      </name>
   </data>

   <data id="marketingsplitting" bean="documentSplitterManager" searchtype="entitymarketingasset" generatedsearchtype="entitymarketingassetpage" enabled="true" ordering="51">
      <name>
         <language id="en"><![CDATA[Marketing Asset Split]]></language>
      </name>
   </data>

   <data id="autotranscribe" bean="whisperTranscriberManager" enabled="true" notes="Transcribe audio or video content with timestamps" ordering="100">
      <name>
         <language id="en"><![CDATA[Auto Transcribe]]></language>
      </name>
   </data>

   <data id="classifyManager" bean="classifyManager" enabled="true" fieldsavevector="vectorarray" aicreationdescription="You are an assistant that analyzes a batch of metadata inputs and identifies a list of topics that describe the underlying concepts, emotions, actions, and themes. Focus on the essence of what is happening — abstract ideas, moods, and relationships — NOT generic object names unless they are essential to the concept. This topics are used for clustering, search, filtering, and recommendations." aifunctionname="generate_metadata" ordering="200">
      <name>
         <language id="en"><![CDATA[Text Classifier]]></language>
      </name>
   </data>


   <data id="autotranslate" bean="translationManager" enabled="true" notes="Translate fields that have values and are multi language" ordering="300">
      <name>
         <language id="en"><![CDATA[Auto Translate]]></language>
      </name>
   </data>

   <data id="semantictopics" bean="semanticClassifier" fieldname="semantictopics" searchtype="semanticembedding" enabled="true" fieldsavevector="vectorarray" aicreationdescription="You are an assistant that analyzes a batch of metadata inputs and identifies a list of topics that describe the underlying concepts, emotions, actions, and themes. Focus on the essence of what is happening — abstract ideas, moods, and relationships — NOT generic object names unless they are essential to the concept. This topics are used for clustering, search, filtering, and recommendations." aicreationcommand="Generate up to 2 semantic topics based on the following metadata:" maxnumberofcentroids="4" init_loop_start_distance=".60" init_loop_lower_limit=".50" maxdistancetocentroid=".67" maxdistancetocentroid_one=".78" maxdistancetomatch=".455" aifunctionname="semantics" ordering="400">
      <name>
         <language id="en"><![CDATA[Semantic Topics]]></language>
      </name>
   </data>

   <data id="actionembedding" searchtype="actionembedding" enabled="false" fieldsavevector="vectorarray" maxnumberofcentroids="4" init_loop_start_distance=".60" init_loop_lower_limit=".50" maxdistancetocentroid=".67" maxdistancetocentroid_one=".78" maxdistancetomatch=".455" aifunctionname="semantics" ordering="1000">
      <name>
         <language id="en"><![CDATA[Semantic Action List]]></language>
      </name>
   </data>

   <data id="namedentityrecognition" bean="namedEntityRecognitionManager" enabled="true" notes="(NER: Named Entity Recognition) is most useful when you need to extract concrete facts (companies, people, places, products) for building indexes, knowledge graphs, or searchable databases" aicreationdescription="You are an information extraction assistant. From the following text, extract a clean list of: Company Names and Place Names (cities, states, countries, or well-known places). Rules: Ignore street addresses, zip codes, URLs, hyperlinks, and email addresses. Do not include personal names (people) or abbreviations of city/states (e.g., CA, NY). Do not include duplicates, return each unique entry once. If no companies or places are found, return an empty array for that field." aicreationcommand="Extract a list of named entities from the following metadata:" aifunctionname="named_entity" ordering="600">
      <name>
         <language id="en"><![CDATA[Named Entity Recognition]]></language>
      </name>
   </data>

   <data id="facedetect" bean="faceProfileManager" searchtype="faceembedding" enabled="true" fieldsavevector="vectorarray" maxnumberofcentroids="4" init_loop_start_distance=".60" init_loop_lower_limit=".50" maxdistancetocentroid=".795" maxdistancetocentroid_one=".835" maxdistancetomatch=".648" notes="Face detection is the process of identifying and locating human faces in images or videos." ordering="700">
      <name>
         <language id="en"><![CDATA[Face Detect]]></language>
      </name>
   </data>

   <data id="documentembedding" bean="documentEmbeddingManager" searchtype="entitydocument" enabled="true" ordering="800">
      <name>
         <language id="en"><![CDATA[Document Embedding]]></language>
      </name>
   </data>

<!--
		if(llmtype.equals("openai"))
		{
			return "https://api.openai.com/v1/chat/completions";
		}
		else if(llmtype.equals("ollama"))
		{
			return "https://ollama.entermediadb.net";
		}
		else if(llmtype.equals("llama"))
		{
			String server = getMediaArchive().getCatalogSettingValue("ai_asset_classification_server");
			return server + "/v1/chat/completions";
		}
		else if(llmtype.equals("llamaopenai"))
		{
			return "https://llamam50.entermediadb.net/v1/chat/completions";
		}
		else if(llmtype.equals("gemini"))
		{
			return "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent";
		}
			
-->
</root>